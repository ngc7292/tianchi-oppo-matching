{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = '4,5,6,7'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from transformers import LineByLineTextDataset\n",
    "from modeling_nezha import NeZhaForSequenceClassification,NeZhaForMaskedLM,NeZhaPreTrainedModel\n",
    "from configuration_nezha import NeZhaConfig"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 数据预处理"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_path = './data/gaiic_track3_round1_train_20210228.tsv'\n",
    "test_path = './data/gaiic_track3_round1_testA_20210228.tsv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab_file = './tokens.txt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_text = './data/raw_text.txt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#统计词频\n",
    "vocab_frequence = {}\n",
    "with open(train_path, encoding=\"utf-8\") as f:\n",
    "    for line in f.read().splitlines():\n",
    "        rows =  line.split('\\t')[0:2]\n",
    "        for sent in rows:\n",
    "            for key in sent.split(' '):\n",
    "                key = key.strip()\n",
    "                vocab_frequence[key] = vocab_frequence.get(key,0)+1 \n",
    "with open(test_path, encoding=\"utf-8\") as f:\n",
    "    for line in f.read().splitlines():\n",
    "        for sent in rows:\n",
    "            for key in sent.split(' '):\n",
    "                key = key.strip()\n",
    "                vocab_frequence[key] = vocab_frequence.get(key,0)+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mini_frequence = 3\n",
    "low_frequence_keys = set()\n",
    "new_vocab = dict()\n",
    "for key in vocab_frequence.keys():\n",
    "    if vocab_frequence[key]<= mini_frequence:\n",
    "        low_frequence_keys.add(key)\n",
    "    else:\n",
    "        new_vocab[key] =  vocab_frequence[key]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_vocab = sorted(new_vocab.items(), key=lambda s: -s[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nezha_orgin_vocab = []\n",
    "with open('./nezha-base-wwm/vocab.txt', encoding=\"utf-8\") as f:\n",
    "    for line in f.read().splitlines():\n",
    "        line = line.strip()\n",
    "        if line != '你':\n",
    "            nezha_orgin_vocab.append(line)\n",
    "        else:\n",
    "            break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab = nezha_orgin_vocab + [key[0] for key in new_vocab]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 生成mlm数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data_pair_sent(path,result):\n",
    "    with open(path, encoding=\"utf-8\") as f:\n",
    "        for line in f.read().splitlines():\n",
    "            rows =  line.split('\\t')[0:2]\n",
    "            a = []\n",
    "            for key in rows[0].split(' '):\n",
    "                key = key.strip()\n",
    "                if key in low_frequence_keys:\n",
    "                    key = '[UNK]'\n",
    "                a.append(key)\n",
    "            b = []\n",
    "            for key in rows[1].split(' '):\n",
    "                key = key.strip()\n",
    "                if key in low_frequence_keys:\n",
    "                    key = '[UNK]'\n",
    "                b.append(key)\n",
    "            result.append(' '.join(a) + ' [SEP] ' +' '.join(b))\n",
    "            result.append(' '.join(b) + ' [SEP] ' +' '.join(a))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_result =[]\n",
    "test_result = []\n",
    "load_data_pair_sent(train_path,train_result)\n",
    "load_data_pair_sent(test_path,test_result)\n",
    "\n",
    "all_result = train_result + test_result\n",
    "with open(raw_text, 'w') as f:\n",
    "    for key in all_result:\n",
    "        f.write(str(key)+'\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(vocab_file,'w') as f:\n",
    "    for key in vocab:\n",
    "        f.write(str(key)+'\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 开始训练"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import BertTokenizer, LineByLineTextDataset\n",
    "tokenizer = BertTokenizer(vocab_file=vocab_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset= LineByLineTextDataset(\n",
    "    tokenizer = tokenizer,\n",
    "    file_path = raw_text,\n",
    "    block_size = 128  # maximum sequence length\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "config = NeZhaConfig.from_pretrained('./nezha-base-wwm/config.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = NeZhaForMaskedLM.from_pretrained('./mynazhe_min_freqence', config=config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def set_only_allow_grad_names(model, layer_names ='emb', freeze=True):\n",
    "#     for name, param in model.named_parameters():\n",
    "#         if layer_names in name:\n",
    "#             param.requires_grad = not freeze"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # 只允许更新embeding层\n",
    "# set_only_allow_grad_names(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers.tokenization_utils_base import BatchEncoding, PaddingStrategy, PreTrainedTokenizerBase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _collate_batch(examples, tokenizer):\n",
    "    \"\"\"Collate `examples` into a batch, using the information in `tokenizer` for padding if necessary.\"\"\"\n",
    "    # Tensorize if necessary.\n",
    "    if isinstance(examples[0], (list, tuple)):\n",
    "        examples = [torch.tensor(e, dtype=torch.long) for e in examples]\n",
    "\n",
    "    # Check if padding is necessary.\n",
    "    length_of_first = examples[0].size(0)\n",
    "    are_tensors_same_length = all(x.size(0) == length_of_first for x in examples)\n",
    "    if are_tensors_same_length:\n",
    "        return torch.stack(examples, dim=0)\n",
    "\n",
    "    # If yes, check if we have a `pad_token`.\n",
    "    if tokenizer._pad_token is None:\n",
    "        raise ValueError(\n",
    "            \"You are attempting to pad samples but the tokenizer you are using\"\n",
    "            f\" ({tokenizer.__class__.__name__}) does not have a pad token.\"\n",
    "        )\n",
    "\n",
    "    # Creating the full tensor and filling it with our data.\n",
    "    max_length = max(x.size(0) for x in examples)\n",
    "    result = examples[0].new_full([len(examples), max_length], tokenizer.pad_token_id)\n",
    "    for i, example in enumerate(examples):\n",
    "        if tokenizer.padding_side == \"right\":\n",
    "            result[i, : example.shape[0]] = example\n",
    "        else:\n",
    "            result[i, -example.shape[0] :] = example\n",
    "    return result\n",
    "\n",
    "class DataCollatorForLanguageModeling:\n",
    "\n",
    "    def __init__(self,tokenizer,mlm=True,mlm_probability=0.15):\n",
    "        self.tokenizer = tokenizer\n",
    "        self.mlm = mlm\n",
    "        self.mlm_probability = mlm_probability\n",
    "\n",
    "    def __call__(self, examples):\n",
    "        # Handle dict or lists with proper padding and conversion to tensor.\n",
    "        if isinstance(examples[0], (dict, BatchEncoding)):\n",
    "            batch = self.tokenizer.pad(examples, return_tensors=\"pt\")\n",
    "        else:\n",
    "            batch = {\"input_ids\": _collate_batch(examples, self.tokenizer)}\n",
    "\n",
    "        # If special token mask has been preprocessed, pop it from the dict.\n",
    "        special_tokens_mask = batch.pop(\"special_tokens_mask\", None)\n",
    "        if self.mlm:\n",
    "            batch[\"input_ids\"], batch[\"masked_lm_labels\"] = self.mask_tokens(\n",
    "                batch[\"input_ids\"], special_tokens_mask=special_tokens_mask\n",
    "            )\n",
    "        else:\n",
    "            labels = batch[\"input_ids\"].clone()\n",
    "            if self.tokenizer.pad_token_id is not None:\n",
    "                labels[labels == self.tokenizer.pad_token_id] = -100\n",
    "            batch[\"masked_lm_labels\"] = labels\n",
    "        return batch\n",
    "\n",
    "    def mask_tokens(self, inputs, special_tokens_mask  = None):\n",
    "        \"\"\"\n",
    "        Prepare masked tokens inputs/labels for masked language modeling: 80% MASK, 10% random, 10% original.\n",
    "        \"\"\"\n",
    "        labels = inputs.clone()\n",
    "        # We sample a few tokens in each sequence for MLM training (with probability `self.mlm_probability`)\n",
    "        probability_matrix = torch.full(labels.shape, self.mlm_probability)\n",
    "        if special_tokens_mask is None:\n",
    "            special_tokens_mask = [\n",
    "                self.tokenizer.get_special_tokens_mask(val, already_has_special_tokens=True) for val in labels.tolist()\n",
    "            ]\n",
    "            special_tokens_mask = torch.tensor(special_tokens_mask, dtype=torch.bool)\n",
    "        else:\n",
    "            special_tokens_mask = special_tokens_mask.bool()\n",
    "\n",
    "        probability_matrix.masked_fill_(special_tokens_mask, value=0.0)\n",
    "        masked_indices = torch.bernoulli(probability_matrix).bool()\n",
    "        labels[~masked_indices] = -100  # We only compute loss on masked tokens\n",
    "\n",
    "        # 80% of the time, we replace masked input tokens with tokenizer.mask_token ([MASK])\n",
    "        indices_replaced = torch.bernoulli(torch.full(labels.shape, 0.8)).bool() & masked_indices\n",
    "        inputs[indices_replaced] = self.tokenizer.convert_tokens_to_ids(self.tokenizer.mask_token)\n",
    "\n",
    "        # 10% of the time, we replace masked input tokens with random word\n",
    "        indices_random = torch.bernoulli(torch.full(labels.shape, 0.5)).bool() & masked_indices & ~indices_replaced\n",
    "        random_words = torch.randint(len(self.tokenizer), labels.shape, dtype=torch.long)\n",
    "        inputs[indices_random] = random_words[indices_random]\n",
    "\n",
    "        # The rest of the time (10% of the time) we keep the masked input tokens unchanged\n",
    "        return inputs, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import BertConfig, BertForMaskedLM\n",
    "\n",
    "data_collator = DataCollatorForLanguageModeling(\n",
    "    tokenizer=tokenizer, mlm=True, mlm_probability=0.15\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import Trainer, TrainingArguments\n",
    "\n",
    "training_args = TrainingArguments(\n",
    "    output_dir='./mynazhe/',\n",
    "    overwrite_output_dir=True,\n",
    "    num_train_epochs=300,\n",
    "    per_device_train_batch_size=128,\n",
    "    save_steps=10_000,\n",
    "    save_total_limit=2,\n",
    "    prediction_loss_only=True,\n",
    "    learning_rate =  5e-6\n",
    ")\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    data_collator=data_collator,\n",
    "    train_dataset=dataset,\n",
    "    \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.train()\n",
    "trainer.save_model(\"./mynazhe_min_freqence\")\n",
    "#loss 0.292800"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.save_model(\"./mynazhe_min_freqence\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 训练"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import RobertaTokenizerFast,BertTokenizerFast,BertTokenizer\n",
    "from torch.utils.data.dataset import Dataset\n",
    "from transformers import DataCollatorForLanguageModeling,DataCollatorWithPadding\n",
    "from transformers import Trainer, TrainingArguments\n",
    "from transformers import RobertaConfig\n",
    "from transformers import RobertaForMaskedLM\n",
    "from transformers import RobertaTokenizerFast,BertTokenizer,RobertaTokenizer\n",
    "from transformers import RobertaModel,BertModel\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from torch.utils.data import DataLoader\n",
    "import math\n",
    "\n",
    "import torch\n",
    "import numpy as np\n",
    "import torch.nn as nn\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_path = './data/gaiic_track3_round1_train_20210228.tsv'\n",
    "test_path = './data/gaiic_track3_round1_testA_20210228.tsv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def load_data(path):\n",
    "    max_length = 0\n",
    "    samples = []\n",
    "    labels = []\n",
    "    with open(path, encoding=\"utf-8\") as f:\n",
    "        for line in f.read().splitlines():\n",
    "            temp = line.split('\\t')\n",
    "            new_line =temp[0] +' [SEP] ' + temp[1]\n",
    "            samples.append(new_line)\n",
    "            if len(temp)>2:\n",
    "                labels.append(int(temp[2]))\n",
    "    return samples,labels,max_length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_texts,train_labels,max_length =  load_data(train_path)\n",
    "test_texts, _, _ = load_data(test_path)\n",
    "from sklearn.model_selection import train_test_split\n",
    "train_texts, val_texts, train_labels, val_labels = train_test_split(train_texts, train_labels, test_size=.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'train: 90000,val:10000'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f'train: {len(train_texts)},val:{len(val_texts)}'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at ./mynazhe_min_freqence were not used when initializing NeZhaForSequenceClassification: ['cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.decoder.weight', 'cls.predictions.decoder.bias']\n",
      "- This IS expected if you are initializing NeZhaForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing NeZhaForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of NeZhaForSequenceClassification were not initialized from the model checkpoint at ./mynazhe_min_freqence and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "tokenizer = BertTokenizer(vocab_file=vocab_file)\n",
    "config = NeZhaConfig.from_pretrained('./mynazhe_min_freqence/config.json',num_labels=2)\n",
    "bert = NeZhaForSequenceClassification.from_pretrained('./mynazhe_min_freqence', config=config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MatchingDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, texts, labels,tokenizer):\n",
    "        self.texts = texts\n",
    "        self.labels = labels\n",
    "    def __getitem__(self, idx):\n",
    "        #item = tokenizer(self.texts[idx])\n",
    "        examples = tokenizer(self.texts[idx], add_special_tokens=True, truncation=True, max_length=max_length)\n",
    "        #examples = batch_encoding\n",
    "        #examples = {\"input_ids\": sent_1['input_ids'],\"input_ids_sent2\":sent_2['input_ids']}\n",
    "        if self.labels:\n",
    "            examples['labels'] = torch.tensor(self.labels[idx], dtype=torch.long)\n",
    "        return examples\n",
    "    def __len__(self):\n",
    "        return len(self.texts)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# class TextMatching(nn.Module):\n",
    "#     def __init__(self, embeding_layer, embeding_size):\n",
    "#         super(TextMatching, self).__init__()\n",
    "#         self.embeding_layer = embeding_layer;\n",
    "#         self.embeding_size = embeding_size\n",
    "#         self.liner = nn.Linear(embeding_size, embeding_size)\n",
    "#         #self.lstm =  nn.LSTM(embeding_size, embeding_size)\n",
    "#         self.dropout = nn.Dropout(0.1)\n",
    "\n",
    "#         self.liner2= nn.Linear(embeding_size, 1)\n",
    "#         #self.criterion = torch.nn.BCEWithLogitsLoss()\n",
    "#         self.sigmoid = nn.Sigmoid()\n",
    "#     def forward(self, input_ids,attention_mask):\n",
    "        \n",
    "#         hidden = self.embeding_layer(input_ids =input_ids,attention_mask=attention_mask)\n",
    "#         print(hidden)\n",
    "#         #hidden = self.lstm(hidden.last_hidden_state)\n",
    "#         hidden = self.dropout(hidden[1])\n",
    "#         hidden = self.liner(hidden)\n",
    "#         hidden = self.liner2(hidden)\n",
    "#         output = self.sigmoid(hidden)\n",
    "#         return output.squeeze()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "NeZhaForSequenceClassification(\n",
       "  (bert): NeZhaModel(\n",
       "    (embeddings): NeZhaEmbeddings(\n",
       "      (word_embeddings): Embedding(21128, 768, padding_idx=0)\n",
       "      (token_type_embeddings): Embedding(2, 768)\n",
       "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (encoder): NeZhaEncoder(\n",
       "      (layer): ModuleList(\n",
       "        (0): NeZhaLayer(\n",
       "          (attention): NeZhaAttention(\n",
       "            (self): NeZhaSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (relative_positions_encoding): RelativePositionsEncoding()\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (1): NeZhaLayer(\n",
       "          (attention): NeZhaAttention(\n",
       "            (self): NeZhaSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (relative_positions_encoding): RelativePositionsEncoding()\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (2): NeZhaLayer(\n",
       "          (attention): NeZhaAttention(\n",
       "            (self): NeZhaSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (relative_positions_encoding): RelativePositionsEncoding()\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (3): NeZhaLayer(\n",
       "          (attention): NeZhaAttention(\n",
       "            (self): NeZhaSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (relative_positions_encoding): RelativePositionsEncoding()\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (4): NeZhaLayer(\n",
       "          (attention): NeZhaAttention(\n",
       "            (self): NeZhaSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (relative_positions_encoding): RelativePositionsEncoding()\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (5): NeZhaLayer(\n",
       "          (attention): NeZhaAttention(\n",
       "            (self): NeZhaSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (relative_positions_encoding): RelativePositionsEncoding()\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (6): NeZhaLayer(\n",
       "          (attention): NeZhaAttention(\n",
       "            (self): NeZhaSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (relative_positions_encoding): RelativePositionsEncoding()\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (7): NeZhaLayer(\n",
       "          (attention): NeZhaAttention(\n",
       "            (self): NeZhaSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (relative_positions_encoding): RelativePositionsEncoding()\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (8): NeZhaLayer(\n",
       "          (attention): NeZhaAttention(\n",
       "            (self): NeZhaSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (relative_positions_encoding): RelativePositionsEncoding()\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (9): NeZhaLayer(\n",
       "          (attention): NeZhaAttention(\n",
       "            (self): NeZhaSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (relative_positions_encoding): RelativePositionsEncoding()\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (10): NeZhaLayer(\n",
       "          (attention): NeZhaAttention(\n",
       "            (self): NeZhaSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (relative_positions_encoding): RelativePositionsEncoding()\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (11): NeZhaLayer(\n",
       "          (attention): NeZhaAttention(\n",
       "            (self): NeZhaSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (relative_positions_encoding): RelativePositionsEncoding()\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (pooler): BertPooler(\n",
       "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "      (activation): Tanh()\n",
       "    )\n",
       "  )\n",
       "  (dropout): Dropout(p=0.1, inplace=False)\n",
       "  (classifier): Linear(in_features=768, out_features=2, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#model = TextMatching(bert,768)\n",
    "bert.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = MatchingDataset(train_texts,train_labels,tokenizer)\n",
    "val_dataset = MatchingDataset(val_texts,val_labels,tokenizer)\n",
    "data_collator = DataCollatorWithPadding(tokenizer)\n",
    "train_loader = DataLoader(train_dataset, batch_size=64, shuffle=True,collate_fn=data_collator)\n",
    "val_loader = DataLoader(val_dataset, batch_size=64, shuffle=True,collate_fn=data_collator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#criterion = nn.BCELoss()\n",
    "lr = 1e-5 # learning rate\n",
    "#optimizer = torch.optim.SGD(model.parameters(), lr=lr)\n",
    "optimizer = torch.optim.Adam(bert.parameters(), lr=lr)\n",
    "scheduler = torch.optim.lr_scheduler.StepLR(optimizer, 1.0, gamma=0.95)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from torch.optim.lr_scheduler import LambdaLR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def reduce_lr(epoch):\n",
    "#     if epoch == 3:\n",
    "#         return 0.1\n",
    "#     return 1\n",
    "# scheduler = LambdaLR(optimizer, lr_lambda=reduce_lr)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# class FGM():\n",
    "#     def __init__(self, model):\n",
    "#         self.model = model\n",
    "#         self.backup = {}\n",
    "\n",
    "#     def attack(self, epsilon=1., emb_name='emb.'):\n",
    "#         # emb_name这个参数要换成你模型中embedding的参数名\n",
    "#         for name, param in self.model.named_parameters():\n",
    "#             if param.requires_grad and emb_name in name:\n",
    "#                 self.backup[name] = param.data.clone()\n",
    "#                 norm = torch.norm(param.grad)\n",
    "#                 if norm != 0:\n",
    "#                     r_at = epsilon * param.grad / norm\n",
    "#                     param.data.add_(r_at)\n",
    "\n",
    "#     def restore(self, emb_name='emb.'):\n",
    "#         # emb_name这个参数要换成你模型中embedding的参数名\n",
    "#         for name, param in self.model.named_parameters():\n",
    "#             if param.requires_grad and emb_name in name: \n",
    "#                 assert name in self.backup\n",
    "#                 param.data = self.backup[name]\n",
    "#         self.backup = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "#fgm = FGM(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "def train(epoch):\n",
    "    bert.train() # Turn on the train mode\n",
    "    total_loss = 0.\n",
    "    start_time = time.time()\n",
    "    for batch_index, batch in enumerate(train_loader):\n",
    "        optimizer.zero_grad()\n",
    "        input_ids = batch['input_ids'].to(device)\n",
    "        attention_mask = batch['attention_mask'].to(device)\n",
    "        labels = batch['labels'].to(device)\n",
    "        #attention_mask = batch['attention_mask'].to(device)\n",
    "        loss, logits  = bert(input_ids,attention_mask,labels=labels)[:2]\n",
    "        loss.backward()\n",
    "        \n",
    "#         fgm.attack() \n",
    "#         output_adv = model(input_ids,attention_mask)\n",
    "#         loss_adv = criterion(output_adv, batch['labels'].to(device))\n",
    "#         loss_adv.backward() # 反向传播，并在正常的grad基础上，累加对抗训练的梯度\n",
    "#         fgm.restore() # 恢复embedding参数\n",
    "        \n",
    "        #torch.nn.utils.clip_grad_norm_(model.parameters(), 0.5)\n",
    "        optimizer.step()\n",
    "        total_loss += loss.item()\n",
    "        log_interval = 200\n",
    "        if batch_index % log_interval == 0 and batch_index > 0:\n",
    "            cur_loss = total_loss / log_interval\n",
    "            elapsed = time.time() - start_time\n",
    "            print('| epoch {:3d} | {:5d}/{:5d} batches | '\n",
    "                  'lr {:02.6f} | ms/batch {:5.2f} | '\n",
    "                  'loss {:5.2f} | ppl {:8.2f}'.format(\n",
    "                    epoch, batch_index, len(train_loader) , scheduler.get_lr()[0],\n",
    "                    elapsed * 1000 / log_interval,\n",
    "                    cur_loss, math.exp(cur_loss)))#scheduler.get_lr()[0]\n",
    "            total_loss = 0\n",
    "            start_time = time.time()\n",
    "\n",
    "\n",
    "def evaluate(eval_model, val_loader):\n",
    "    eval_model.eval() \n",
    "    y_pred = []\n",
    "    y_true = []\n",
    "    with torch.no_grad():\n",
    "        for batch in val_loader:\n",
    "            input_ids = batch['input_ids'].to(device)\n",
    "            attention_mask = batch['attention_mask'].to(device)\n",
    "            output = eval_model(input_ids,attention_mask)[0]\n",
    "            output = output.cpu().numpy()\n",
    "            #output_score = np.exp(output[:, 1])/ (np.exp(output).sum(axis=1))\n",
    "            output_score = np.exp(output)/ (np.exp(output).sum(axis=1,keepdims=True))\n",
    "            y_pred.append(output_score[:, 1]/output_score.sum(axis=1))\n",
    "            y_true.append(batch['labels'].numpy())\n",
    "    y_pred = np.concatenate(y_pred)\n",
    "    y_true = np.concatenate(y_true)\n",
    "    return roc_auc_score(y_true, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_val_auc = float(\"inf\")\n",
    "epochs = 10\n",
    "best_model = None\n",
    "for epoch in range(1, epochs + 1):\n",
    "    epoch_start_time = time.time()\n",
    "    train()\n",
    "    val_auc = evaluate(bert, val_loader)\n",
    "    print('-' * 89)\n",
    "    print('| end of epoch {:3d} | time: {:5.2f}s | valid auc {:5.5f}  '.format(epoch, (time.time() - epoch_start_time),val_auc))\n",
    "    print('-' * 89)\n",
    "\n",
    "    if val_auc > best_val_auc:\n",
    "        best_val_loss = val_auc\n",
    "        best_model = model\n",
    "    #scheduler.step()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9591093476755004"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluate(bert, val_loader)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dataset = MatchingDataset(test_texts,None,tokenizer)\n",
    "test_loader = DataLoader(test_dataset, batch_size=64, shuffle=False,collate_fn=data_collator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "bert.eval() \n",
    "y_pred = []\n",
    "with torch.no_grad():\n",
    "    for batch_index, batch in enumerate(test_loader):\n",
    "        input_ids = batch['input_ids'].to(device)\n",
    "        attention_mask = batch['attention_mask'].to(device)\n",
    "        output = bert(input_ids,attention_mask)[0]\n",
    "        output = output.cpu().numpy()\n",
    "        #output_score = np.exp(output[:, 1])/ (np.exp(output).sum(axis=1))\n",
    "        output_score = np.exp(output)/ (np.exp(output).sum(axis=1,keepdims=True))\n",
    "        y_pred.append(output_score[:, 1]/output_score.sum(axis=1))\n",
    "y_pred = np.concatenate(y_pred)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('./result.txt', 'w') as f:\n",
    "    for val in y_pred:\n",
    "        f.write(str(val)+'\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nlp",
   "language": "python",
   "name": "nlp"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}